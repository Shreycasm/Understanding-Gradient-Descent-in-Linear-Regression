# Understanding-Gradient-Descent-in-Linear-Regression
This repository contains a Jupyter notebook that explores the Gradient Descent algorithm for Linear Regression. The notebook provides insights into the optimization process for linear regression parameters and compares it with the Ordinary Least Squares (OLS) method.

Overview

The main goal of this notebook is to understand the Gradient Descent algorithm's application in optimizing the parameters (slope and intercept) of a linear regression model.
Why Gradient Descent?
OLS provides an analytical solution to linear regression, but it may become computationally expensive with large datasets.
Gradient Descent offers an iterative optimization approach, often more efficient for large datasets and complex models.
Explored the impact of learning rates on convergence and demonstrated scenarios where Gradient Descent proves advantageous.
